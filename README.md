# deep-fMC_paper

This repository contains experiments and analysis related to the publication in https://www.biorxiv.org/content/10.1101/2025.01.29.635381v1

Data files for input and output from exp files can be found at https://osf.io/tvu52/

## Repository structure

### 1. `data`
- **Purpose**: Holds input data files for experiments, as well as outputs generated from the experiments (available at https://osf.io/tvu52/)

### 2. `exp`
- **Purpose**: Contains experiment notebooks, scripts, and their direct outputs. Each subfolder (e.g., `exp01`, `exp02`, etc.) corresponds to a set of related analyses, ordered when possible.

### 3. `figures`
- **Purpose**: Stores figures generated by each experiment, organized by experiment folder (e.g., `exp01`, `exp02`, etc.). Inside each experiment folder, figures may be further grouped by notebook number (e.g., `1_figures`, `3_figures`, `4_figures`).

### 4. `scripts`
- **Purpose**: Contains utility scripts or modules that provide functions used across experiments.

## Installation guide

The model we used can be found in https://github.com/AprilYuge/scAAnet/blob/main/

The conda enviroment used to train the model had python 3.10.11, tensorflow 2.10.0 and cuda-version 11.8. We recommend cloning the repo instead of trying to install scAAnet using pip

```bash
conda create -n scAAnet python=3.10.11 -y && conda activate scAAnet && pip install tensorflow==2.10.0 && conda install -c conda-forge cudatoolkit=11.8 cudnn=8.8.0.121 -y
```

### If using local machine to clone scAAnet repo

```bash
git clone https://github.com/AprilYuge/scAAnet.git 
```

### If using ssh to clone scAAnet repo
```bash
git clone git@github.com:AprilYuge/scAAnet.git 
```

## Running the trained model to call functional archetypes in your own dataset

You will need to have pathway relative abundance obtained from HUMAnN3 and formatted as a [AnnData object](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html)

Below is a sample code snippet (from `exp/exp04_exp04_preprocess_and_deepaa_with_disease/3_deepaa_model_disease_analysis.ipynb`) showing how to load and use the trained model. Make sure to replace any paths and variable names with your actual locations and data.

```python
import numpy as np
from tensorflow.keras.models import load_model
#if you cloned the scAAnet repo and replaced the network file with modified_network.py use:
#sys.path.append('../../scAAnet') 
#from network import ZFixedLayer, DispLayer, DispAct, create_z_fixed, ColwiseMultLayer
#else use: 
#modified_network.py is a modified version of the top section of https://github.com/AprilYuge/scAAnet/blob/main/scAAnet/network.py to allow model saving and loading as .h5 file 
sys.path.append('../../scripts')
from modified_network import ZFixedLayer, DispLayer, DispAct, create_z_fixed, ColwiseMultLayer 

# features_model_trained_on.csv contains the pathways that the model needs and was trained on
# concat_ad is an anndata object of your samples 
if isinstance(concat_ad, ad.AnnData):
    if sp.issparse(concat_ad.X):
        concat_ad = concat_ad.X.todense()
    else:
        concat_ad = concat_ad.X
count_samples = np.asmatrix(concat_ad).astype('float32')

# Convert counts to TPM by dividing by the sum of counts per sample
TPM_samples = count_samples / count_samples.sum(axis=1)

# Calculate the library size (sum of all counts per sample)
lib_size_samples = count_samples.sum(axis=1)

model_path = "../../data/scAAnet_output"
# Load the trained model to get reconstruction of count matrix
model = load_model(
    f"{model_path}/model.h5",
    custom_objects={
        "ZFixedLayer": ZFixedLayer,
        "DispLayer": DispLayer,
        "DispAct": DispAct,
        "create_z_fixed": create_z_fixed
    }
)
recon = model.predict({"nor_count": TPM_samples, "lib_size": lib_size_samples})

# Load and run the encoder to get samples' archetype usage 
encoder = load_model(
    f"{model_path}/trained_encoder.h5",
    custom_objects={
        "ZFixedLayer": ZFixedLayer,
        "DispLayer": DispLayer,
        "DispAct": DispAct,
        "create_z_fixed": create_z_fixed
    }
)
usage = encoder.predict({"nor_count": TPM_samples, "lib_size": TPM_samples})

# Load and run the decoder to get the spectra of the archetypes 
decoder = load_model(
    f"{model_path}/trained_decoder.h5",
    custom_objects={
        "ZFixedLayer": ZFixedLayer,
        "DispLayer": DispLayer,
        "DispAct": DispAct,
        "create_z_fixed": create_z_fixed
    }
)
# Retrieve the latent representation from the model
z_fixed_weights = model.get_layer("z_fixed").get_weights()[0]
spectra = decoder.predict(z_fixed_weights)
